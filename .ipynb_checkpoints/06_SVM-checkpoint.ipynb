{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f7a31be-f94b-4087-9536-a3f0c6b24080",
   "metadata": {},
   "source": [
    "# SVM Implementation PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c7a7903-a65e-44f5-81c4-d6f773fa4522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d2ad133-b86c-4d67-9326-f32b512643e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"./data/Admission_Predict.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e0b9e8e-befd-4a59-9884-c87498488f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Chance of Admit ']  = df['Chance of Admit '].apply(lambda x: 1 if x >= 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b0c285a-81c0-4604-8c4c-25bf5316ca70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1                 1  \n",
       "1         1                 1  \n",
       "2         1                 1  \n",
       "3         1                 1  \n",
       "4         0                 1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9682f358-c903-49b2-b0fd-019c7bee25d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    367\n",
       "0     33\n",
       "Name: Chance of Admit , dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,-1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d7971cc-e389-4c23-9b02-81b7b22ff1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
       "       'LOR ', 'CGPA', 'Research', 'Chance of Admit '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b259226f-c4c0-47be-8970-2c722c17043b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       " 0           1        337          118                  4  4.5   4.5  9.65   \n",
       " 1           2        324          107                  4  4.0   4.5  8.87   \n",
       " 2           3        316          104                  3  3.0   3.5  8.00   \n",
       " 3           4        322          110                  3  3.5   2.5  8.67   \n",
       " 4           5        314          103                  2  2.0   3.0  8.21   \n",
       " \n",
       "    Research  \n",
       " 0         1  \n",
       " 1         1  \n",
       " 2         1  \n",
       " 3         1  \n",
       " 4         0  ,\n",
       " 0    1\n",
       " 1    1\n",
       " 2    1\n",
       " 3    1\n",
       " 4    1\n",
       " Name: Chance of Admit , dtype: int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df.drop('Chance of Admit ', axis = 1), df['Chance of Admit ']\n",
    "X.head(), y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c912932a-cb9b-4e3e-8c7a-e211277a24e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 8), (400,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab8a6eaf-aa10-44d7-a316-9f57e3d0326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = X.columns\n",
    "for var in vars:\n",
    "    X[f\"{var}\"] = X[f\"{var}\"]/ X[f\"{var}\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b57976f0-9098-43a7-8aa2-90a44f7fe56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.991176</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.972782</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.894153</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.947059</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.873992</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.923529</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.827621</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR       CGPA  \\\n",
       "0      0.0025   0.991176     0.983333                0.8  0.9   0.9  0.972782   \n",
       "1      0.0050   0.952941     0.891667                0.8  0.8   0.9  0.894153   \n",
       "2      0.0075   0.929412     0.866667                0.6  0.6   0.7  0.806452   \n",
       "3      0.0100   0.947059     0.916667                0.6  0.7   0.5  0.873992   \n",
       "4      0.0125   0.923529     0.858333                0.4  0.4   0.6  0.827621   \n",
       "\n",
       "   Research  \n",
       "0       1.0  \n",
       "1       1.0  \n",
       "2       1.0  \n",
       "3       1.0  \n",
       "4       0.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45e2d9f-ee63-43d5-a139-2cca2e6c3500",
   "metadata": {},
   "source": [
    "## Prepare DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b584fa45-8c3b-4370-8fb2-303db795a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "# Generate a synthetic dataset for demonstration\n",
    "# X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "922dd64f-63d1-4ddb-8e34-49aecdc8d72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_data_loader = DataLoader(dataset = X_train,\n",
    "                              batch_size = BATCH_SIZE,\n",
    "                              shuffle = True)\n",
    "test_data_loader = DataLoader(dataset = X_test,\n",
    "                              batch_size = BATCH_SIZE,\n",
    "                              shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49674c29-6bd2-45ee-b41b-0ace6b147985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader: (<torch.utils.data.dataloader.DataLoader object at 0x0000029D691D4DC0>, <torch.utils.data.dataloader.DataLoader object at 0x0000029D6CF72DD0>)\n",
      "Length of train dataloader: 10 of BATCH_SIZE: 32\n",
      "Length of test dataloader: 3 of BATCH_SIZE: 32\n"
     ]
    }
   ],
   "source": [
    "# Let's check out what we've create\n",
    "print(f\"DataLoader: {train_data_loader, test_data_loader}\")\n",
    "print(f\"Length of train dataloader: {len(train_data_loader)} of BATCH_SIZE: {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_data_loader)} of BATCH_SIZE: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9bb6bbf1-6306-458a-9b03-bd6b67eb2970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "975534c0-010e-4f22-81e6-a5a4e27a9b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Classifier Model\n",
    "class SVM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SVM, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "# Create an SVM model instance\n",
    "model = SVM(input_size=8, hidden_size=10, output_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c061916d-a103-4694-a004-0487e9580c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_test, y_test_pred):\n",
    "    return (y_test_pred.round() == y_test).float().mean()\n",
    "\n",
    "\n",
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader : torch.utils.data.DataLoader,\n",
    "               y: torch.Tensor,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "  \"\"\"Calculates the training computation of a PyTorch model\n",
    "  Arge:\n",
    "    model: A pytorch class for model\n",
    "    data_loader: The dataloader of pytorch\n",
    "    loss_fn: Loss function for the model\n",
    "    optimzer: optimizer of the loss\n",
    "    accuracy_fn: Accuracy function for calculation\n",
    "    devic: Device agnostic code cuda or cpu\n",
    "  \"\"\"\n",
    "  train_loss, train_acc = 0, 0\n",
    "  model.to(device)\n",
    "  for batch, X in enumerate(data_loader):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    # 1. Forward pass\n",
    "    y_pred = model(X)\n",
    "    # 2. Calculate the loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    train_loss += loss\n",
    "    train_acc = accuracy_fn(y_true = y, y_pred =y_pred.argmax(dim = 1))\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "    # 4. Loss backward\n",
    "    loss.backward()\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "  # Calculate the loss and accuracy per epoch and print out what's happening\n",
    "  train_loss /= len(data_loader)\n",
    "  train_acc /= len(data_loader)\n",
    "  print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "def test_step(model:torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              y: torch.Tensor,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "  \"\"\"Calculates the training computation of a PyTorch model\n",
    "  Arge:\n",
    "    model: A pytorch class for model\n",
    "    data_loader: The dataloader of pytorch\n",
    "    loss_fn: Loss function for the model\n",
    "    optimzer: optimizer of the loss\n",
    "    accuracy_fn: Accuracy function for calculation\n",
    "    devic: Device agnostic code cuda or cpu\n",
    "  \"\"\"\n",
    "  test_loss, test_acc = 0, 0\n",
    "  model.to(device)\n",
    "  model.eval()\n",
    "  with torch.inference_mode():\n",
    "    for X in data_loader:\n",
    "      X, y = X.to(device), y.to(device)\n",
    "      # 1. forward pass\n",
    "      test_pred = model(X)\n",
    "      # 2. Calculate loss and accuracy\n",
    "      test_loss = loss_fn(test_pred, y)\n",
    "      test_acc += accuracy_fn(y_true = y, y_pred = test_pred.argmax(dim = 1)) # Go from logitrs -> pred labels\n",
    "    # Adjust metrics and print out what's happening\n",
    "    test_loss /= len(data_loader)\n",
    "    test_acc /= len(data_loader)\n",
    "    print(f\"Test loss: {test_loss:.5f} | Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a04fb74-3cf2-41bd-a219-a7bc9ce24f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf895ba1-62e9-4fe7-a69a-c272b52da91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ff941a1f6540c38e76eefa3aaa9700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([320])) must be the same as input size (torch.Size([32, 1]))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs)):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m             \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m             \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m             \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m             \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m             \u001b[49m\u001b[43maccuracy_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maccuracy_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     test_step(data_loader \u001b[38;5;241m=\u001b[39m test_data_loader,\n\u001b[0;32m     17\u001b[0m                 y \u001b[38;5;241m=\u001b[39m y_test,\n\u001b[0;32m     18\u001b[0m                 model \u001b[38;5;241m=\u001b[39m model,\n\u001b[0;32m     19\u001b[0m                 loss_fn \u001b[38;5;241m=\u001b[39m loss_fn,\n\u001b[0;32m     20\u001b[0m                 accuracy_fn \u001b[38;5;241m=\u001b[39m accuracy_fn)\n",
      "Cell \u001b[1;32mIn[55], line 28\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, data_loader, y, loss_fn, optimizer, accuracy_fn, device)\u001b[0m\n\u001b[0;32m     26\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 2. Calculate the loss\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     30\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m accuracy_fn(y_true \u001b[38;5;241m=\u001b[39m y, y_pred \u001b[38;5;241m=\u001b[39my_pred\u001b[38;5;241m.\u001b[39margmax(dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mG:\\0001_installed_softwares\\004_anaconda\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mG:\\0001_installed_softwares\\004_anaconda\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mG:\\0001_installed_softwares\\004_anaconda\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\loss.py:734\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\0001_installed_softwares\\004_anaconda\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\functional.py:3242\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   3239\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[1;32m-> 3242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[1;31mValueError\u001b[0m: Target size (torch.Size([320])) must be the same as input size (torch.Size([32, 1]))"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# tqdm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n...\")\n",
    "    train_step(data_loader = train_data_loader,\n",
    "             model = model,\n",
    "             y = y_train,\n",
    "             loss_fn = loss_fn,\n",
    "             optimizer = optimizer,\n",
    "             accuracy_fn = accuracy_fn)\n",
    "    test_step(data_loader = test_data_loader,\n",
    "                y = y_test,\n",
    "                model = model,\n",
    "                loss_fn = loss_fn,\n",
    "                accuracy_fn = accuracy_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28711b14-21a6-4687-ae00-c82a638cead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaba6691-2f8e-41cd-b601-8547e92939ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a390e3b-f25e-4e14-b60f-a2871dba1579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65da7cd6-b1fd-4bb2-823b-e6d46a983a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dfe784-d85d-44d6-a313-7d0dc62a1fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
